# application.yml
spring:
  kafka:
    consumer:
      bootstrap-servers: ${KAFKA_BOOTSTRAP}
      group-id: event-service-v1
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
      value-deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
      # Pull tuning
      max-poll-records: 500          # start 200–1000; tune with latency
      fetch-min-bytes: 65536         # coalesce small messages
      fetch-max-wait-ms: 50          # wait a bit to batch
      max-partition-fetch-bytes: 1048576  # align with typical message size
      # Stability
      session-timeout-ms: 15000
      heartbeat-interval-ms: 5000
      auto-offset-reset: latest
      partition-assignment-strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor





// KafkaConsumerConfig.java
@Bean
ConcurrentKafkaListenerContainerFactory<byte[], byte[]> byteConsumerFactory(
        ConsumerFactory<byte[], byte[]> cf) {
    var f = new ConcurrentKafkaListenerContainerFactory<byte[], byte[]>();
    f.setConsumerFactory(cf);
    f.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);
    f.getContainerProperties().setObservationEnabled(true); // Micrometer
    f.setConcurrency(3);                 // start = min( #partitions, CPU cores ), then tune
    f.setCommonErrorHandler(new DefaultErrorHandler(
        // backoff between redeliveries (framework level); you’ll still DLQ in your code
        new ExponentialBackOffWithMaxRetries(3) {{ setInitialInterval(200); setMultiplier(2.0); setMaxInterval(3000); }}
    ));
    // Optional: pause/resume on processor backpressure
    f.setContainerCustomizer(container -> container.setPauseImmediate(true));
    return f;
}
